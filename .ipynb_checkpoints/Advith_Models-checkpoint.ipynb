{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hinge, l2: 0.63499\n",
      "hinge, l1: 0.64087\n",
      "hinge, elasticnet: 0.61144\n",
      "log, l2: 0.61312\n",
      "log, l1: 0.62994\n",
      "log, elasticnet: 0.61817\n",
      "modified_huber, l2: 0.63162\n",
      "modified_huber, l1: 0.61060\n",
      "modified_huber, elasticnet: 0.62742\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "# CONSTANTS\n",
    "LOSSES = [\"hinge\", \"log\", \"modified_huber\"]\n",
    "PENALTIES = [\"l2\", \"l1\", \"elasticnet\"]\n",
    "RUNS = 2000\n",
    "\n",
    "data = np.loadtxt(\"training_data.txt\", delimiter=\"|\", skiprows=1)\n",
    "trainingX = data[0:3000, 0:-1]\n",
    "trainingY = data[0:3000, -1]\n",
    "\n",
    "testX = data[3000:, 0:-1]\n",
    "testY = data[3000:, -1]\n",
    "\n",
    "# Error function as a fraction\n",
    "def erf(a1, a2):\n",
    "    total = 0\n",
    "    for x in range(len(a1)):\n",
    "        if a1[x] == a2[x]:\n",
    "            total += 1\n",
    "    return float(total)/len(a1)\n",
    "\n",
    "# Loss and penalty terms\n",
    "def res(l, p, runs):\n",
    "    clf = SGDClassifier(loss=l, penalty=p)\n",
    "    clf.fit(trainingX, trainingY)\n",
    "    error = 0\n",
    "    for x in range(runs):\n",
    "        error += erf(clf.predict(testX), testY)\n",
    "    return error/runs\n",
    "\n",
    "# Prints testing results\n",
    "def test(losses, penalties, runs):\n",
    "    for loss in losses:\n",
    "        for penalty in penalties:\n",
    "            val = res(loss, penalty, runs)\n",
    "            print \"%s, %s: %0.5f\" %(loss, penalty, val)\n",
    "\n",
    "test(LOSSES, PENALTIES, RUNS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For testing for submission\n",
    "\n",
    "test_data = np.loadtxt(\"testing_data.txt\", delimiter=\"|\", skiprows=1)\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "l, p = \"modified_huber\", \"l2\" # Optimal choices\n",
    "clf_test = SGDClassifier(loss=l, penalty=p)\n",
    "clf_test.fit(trainingX, trainingY)\n",
    "prediction = clf.predict(test_data)\n",
    "\n",
    "f = open(\"results.csv\", \"w\")\n",
    "f.write(\"Id,Prediction\\n\")\n",
    "for x in range(len(prediction)):\n",
    "    f.write(str(x+1) + \",\" + str(int(prediction[x])) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
