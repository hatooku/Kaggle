{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Sentiment Analysis Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import time\n",
    "import os\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load training and test data (80/20 Split)\n",
    "data = np.loadtxt(\"training_data.txt\", delimiter=\"|\", skiprows=1)\n",
    "dataX = data[:, 0:-1]\n",
    "dataY = data[:, -1]\n",
    "training_size = int(data.shape[0] * 0.8)\n",
    "\n",
    "trainingX = data[0:training_size, 0:-1]\n",
    "trainingY = data[0:training_size, -1]\n",
    "\n",
    "testX = data[training_size:, 0:-1]\n",
    "testY = data[training_size:, -1]\n",
    "\n",
    "# For testing for submission\n",
    "\n",
    "test_data = np.loadtxt(\"testing_data.txt\", delimiter=\"|\", skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "\n",
    "# lambdas \n",
    "lambdas_arr = np.arange(500, 1000, 0.1)\n",
    "\n",
    "#clf = RidgeClassifierCV(alphas=lambdas_arr, cv=5)\n",
    "#clf.fit(dataX, dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print clf.score(trainingX, trainingY)\n",
    "#print clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ridge Prediction\n",
    "prediction = clf.predict(test_data)\n",
    "\n",
    "f = open(\"RidgeCV.csv\", \"w\")\n",
    "f.write(\"Id,Prediction\\n\")\n",
    "for x in range(len(prediction)):\n",
    "    f.write(str(x+1) + \",\" + str(int(prediction[x])) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_arr = []\n",
    "test_arr = []\n",
    "estimator_arr = range(200, 1000, 10)\n",
    "\n",
    "for i in estimator_arr:\n",
    "    ada = AdaBoostClassifier(n_estimators=i, learning_rate=1)\n",
    "    ada.fit(trainingX, trainingY)\n",
    "    training_arr.append(ada.score(trainingX, trainingY))\n",
    "    test_arr.append(ada.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(estimator_arr, training_arr)\n",
    "plt.plot(estimator_arr, test_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print np.argmax(np.array(test_arr))\n",
    "print estimator_arr[np.argmax(np.array(test_arr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada1 = AdaBoostClassifier(n_estimators=estimator_arr[np.argmax(np.array(test_arr))], learning_rate=1)\n",
    "ada1.fit(trainingX, trainingY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction1 = ada1.predict(test_data)\n",
    "\n",
    "f = open(\"AdaBoostDecisionTree.csv\", \"w\")\n",
    "f.write(\"Id,Prediction\\n\")\n",
    "for x in range(len(prediction)):\n",
    "    f.write(str(x+1) + \",\" + str(int(prediction1[x])) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up lists to store training errors and test errors.\n",
    "num_estimators_train_error = []\n",
    "num_estimators_tests_error = []\n",
    "\n",
    "# Train models with different minimum leaf sizes and record\n",
    "# scores on the models.\n",
    "min_n_estimators = 1\n",
    "max_n_estimators = 200\n",
    "step_size = 10\n",
    "num_trials = 5\n",
    "for n_estimator in np.arange(min_n_estimators, max_n_estimators, step_size):\n",
    "    # Run trials for each minimum leaf size and average the values.\n",
    "    train_trial_errors = []\n",
    "    tests_trial_errors = []\n",
    "    for i in range(0, num_trials):\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimator, n_jobs=-1)\n",
    "        clf.fit(trainingX, trainingY)\n",
    "        train_trial_errors.append(1 - clf.score(trainingX, trainingY))\n",
    "        tests_trial_errors.append(1 - clf.score(testX, testY))\n",
    "    num_estimators_train_error.append(np.mean(train_trial_errors))\n",
    "    num_estimators_tests_error.append(np.mean(tests_trial_errors))\n",
    "print num_estimators_train_error\n",
    "print num_estimators_tests_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.figure(4, figsize=(8, 6))\n",
    "plt.plot(np.arange(min_n_estimators, max_n_estimators, step_size), num_estimators_train_error, label='Training Error')\n",
    "plt.plot(np.arange(min_n_estimators, max_n_estimators, step_size), num_estimators_tests_error, label='Test Error')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Error Versus Number of Estimators')\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a model based on best results from above\n",
    "randfor_model1 = RandomForestClassifier(n_estimators=100)\n",
    "randfor_model1.fit(dataX, dataY)\n",
    "\n",
    "# Predict data and write to file.\n",
    "randfor_predict1 = randfor_model1.predict(test_data)\n",
    "\n",
    "f = open(\"RandomForestJoon.csv\", \"w\")\n",
    "f.write(\"Id,Prediction\\n\")\n",
    "for x in range(len(randfor_predict1)):\n",
    "    f.write(str(x+1) + \",\" + str(int(randfor_predict1[x])) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up lists to store training errors and test errors.\n",
    "num_estimators_train_error = []\n",
    "num_estimators_tests_error = []\n",
    "\n",
    "# Train models with different minimum leaf sizes and record\n",
    "# scores on the models.\n",
    "for i in range(1, 60, 1):\n",
    "    # Run trials for each minimum leaf size and average the values.\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_leaf=i, max_features=62, n_jobs=-1)\n",
    "    clf.fit(trainingX, trainingY)\n",
    "    num_estimators_train_error.append(1 - clf.score(trainingX, trainingY))\n",
    "    num_estimators_tests_error.append(1 - clf.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.figure(4, figsize=(8, 6))\n",
    "plt.plot(range(1, 60, 1), num_estimators_train_error, label='Training Error')\n",
    "plt.plot(range(1, 60, 1), num_estimators_tests_error, label='Test Error')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Max Feature')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randfor_model1 = RandomForestClassifier(n_estimators=10000000, min_samples_leaf=5, max_features=62, n_jobs=-1)\n",
    "randfor_model1.fit(dataX, dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict data and write to file.\n",
    "randfor_predict1 = randfor_model1.predict(test_data)\n",
    "\n",
    "f = open(\"RandomForestJoon4.csv\", \"w\")\n",
    "f.write(\"Id,Prediction\\n\")\n",
    "for x in range(len(randfor_predict1)):\n",
    "    f.write(str(x+1) + \",\" + str(int(randfor_predict1[x])) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=5000, min_samples_leaf=5, max_features=62, n_jobs=-1, criterion='gini')\n",
    "rf2 = RandomForestClassifier(n_estimators=5000, min_samples_leaf=5, max_features=62, n_jobs=-1, criterion='entropy')\n",
    "et1 = ExtraTreesClassifier(n_estimators=5000, min_samples_leaf=5, max_features=62, n_jobs=-1, criterion='gini')\n",
    "et2 = ExtraTreesClassifier(n_estimators=5000, min_samples_leaf=5, max_features=62, n_jobs=-1, criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf1', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=62, max_leaf_nodes=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=-1,\n",
       "            o...ators=5000, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))],\n",
       "         voting='hard', weights=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf1 = VotingClassifier(estimators=[('rf1', rf1), ('rf2', rf2), ('et1', et1), ('et2', et2)], voting='hard')\n",
    "eclf1.fit(dataX, dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.genfromtxt(\"VotingTest.csv\", delimiter=',', dtype=int)[:, 1]\n",
    "one = np.genfromtxt(\"Joon/Voting1.csv\", delimiter=',', dtype=int)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1349\n",
      "7\n",
      "0.00516224188791\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "wrong = 0\n",
    "for i in range(test.shape[0]):\n",
    "    if test[i] == one[i]:\n",
    "        right +=1\n",
    "    else:\n",
    "        wrong += 1\n",
    "print right\n",
    "print wrong\n",
    "print wrong*1.0/(right + wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix( trainingX, label=trainingY)\n",
    "dtest = xgb.DMatrix(testX, label=testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {'max_depth': 3, 'colsample_bytree': 0.5, 'silent':1, 'objective':'binary:logistic'}\n",
    "param['eval_metric'] = 'error'\n",
    "watchlist  = [(dtest,'test'), (dtrain,'train')]\n",
    "bst = xgb.train(param, dtrain, 260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgpreds = np.around(bst.predict(dtest))\n",
    "labels = dtest.get_label()\n",
    "print ('score=%f' % (1- sum(1 for i in range(len(xgpreds)) if int(xgpreds[i]>0.5)!=labels[i]) /float(len(xgpreds))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [22, 27, 32, 37, 42, 47, 52, 57, 62, 67, 72, 77, 82, 87, 92], 'min_samples_leaf': [1, 5, 9, 13, 17, 21, 25, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest (Gini)\n",
    "rf_gini = RandomForestClassifier(n_estimators=100, criterion='gini')\n",
    "params1 = {'min_samples_leaf': range(1, 30, 4), 'max_features': range(22, 93, 5)}\n",
    "rf_gini_grid = GridSearchCV(estimator=rf_gini, param_grid = params1, cv = 5, n_jobs=-1)\n",
    "rf_gini_grid.fit(dataX, dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [22, 27, 32, 37, 42, 47, 52, 57, 62, 67, 72, 77, 82, 87, 92], 'min_samples_leaf': [1, 5, 9, 13, 17, 21, 25, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest (Entropy)\n",
    "rf_entropy = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "rf_entropy_grid = GridSearchCV(estimator=rf_entropy, param_grid = params1, cv = 5, n_jobs=-1)\n",
    "rf_entropy_grid.fit(dataX, dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [22, 27, 32, 37, 42, 47, 52, 57, 62, 67, 72, 77, 82, 87, 92], 'min_samples_leaf': [1, 5, 9, 13, 17, 21, 25, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extra Trees (Gini)\n",
    "et_gini = ExtraTreesClassifier(n_estimators=100, criterion='gini')\n",
    "params1 = {'min_samples_leaf': range(1, 30, 4), 'max_features': range(22, 93, 5)}\n",
    "et_gini_grid = GridSearchCV(estimator=et_gini, param_grid = params1, cv = 5, n_jobs=-1)\n",
    "et_gini_grid.fit(dataX, dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [22, 27, 32, 37, 42, 47, 52, 57, 62, 67, 72, 77, 82, 87, 92], 'min_samples_leaf': [1, 5, 9, 13, 17, 21, 25, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extra Trees (Entropy)\n",
    "et_entropy = ExtraTreesClassifier(n_estimators=100, criterion='entropy')\n",
    "et_entropy_grid = GridSearchCV(estimator=et_entropy, param_grid = params1, cv = 5, n_jobs=-1)\n",
    "et_entropy_grid.fit(dataX, dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "params2 = {\n",
    "    'max_depth': range(4, 12),\n",
    "    'learning_rate': [0.3, 0.2, 0.15, 0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "    'colsample_bytree': np.arange(0.3, 0.55, 0.05),\n",
    "    'min_child_weight': range(4, 15, 2)\n",
    "}\n",
    "\n",
    "xg = XGBClassifier(n_estimators=100)\n",
    "xg_grid = GridSearchCV(estimator=xg, param_grid = params2, cv = 5, n_jobs=-1)\n",
    "xg_grid.fit(dataX, dataY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_gini_predict = rf_gini_grid.predict(test_data)\n",
    "rf_entropy_predict = rf_entropy_grid.predict(test_data)\n",
    "et_gini_predict = et_gini_grid.predict(test_data)\n",
    "et_entropy_predict = et_entropy_grid.predict(test_data)\n",
    "xg_predict = xg_grid.predict(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_vote = np.around(np.average(np.vstack(rf_gini_predict, rf_entropy_predict, et_gini_predict, et_entropy_predict, xg_predict), axis=0))\n",
    "\n",
    "f = open(\"GridVoting.csv\", \"w\")\n",
    "f.write(\"Id,Prediction\\n\")\n",
    "for x in range(len(vote_predict1)):\n",
    "    f.write(str(x+1) + \",\" + str(int(vote_predict1[x])) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=42, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features=27, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features=67, max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features=27, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print rf_gini_grid.best_estimator_\n",
    "print rf_entropy_grid.best_estimator_\n",
    "print et_gini_grid.best_estimator_\n",
    "print rf_entropy_grid.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 42, 'min_samples_leaf': 1}\n",
      "{'max_features': 27, 'min_samples_leaf': 1}\n",
      "{'max_features': 67, 'min_samples_leaf': 1}\n",
      "{'max_features': 27, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "print rf_gini_grid.best_params_\n",
    "print rf_entropy_grid.best_params_\n",
    "print et_gini_grid.best_params_\n",
    "print rf_entropy_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-68e12252162e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mrf_gini_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mrf_entropy_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0met_gini_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0met_entropy_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "print rf_gini_grid.best_score_\n",
    "print rf_entropy_grid.best_score_\n",
    "print et_gini_grid.best_score_\n",
    "print et_entropy_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_gini = RandomForestClassifier(n_estimators=10000, min_samples_leaf=5, max_features=42, criterion='gini')\n",
    "rf_entropy = RandomForestClassifier(n_estimators=10000, min_samples_leaf=5, max_features=27, criterion='entropy')\n",
    "et_gini = ExtraTreesClassifier(n_estimators=10000, min_samples_leaf=5, max_features=67, criterion='gini')\n",
    "et_entropy = RandomForestClassifier(n_estimators=10000, min_samples_leaf=5, max_features=27, criterion='entropy')\n",
    "\n",
    "voting1 = VotingClassifier(estimators=[('rf_gini', rf_gini), ('rf_entropy', rf_entropy), ('et_gini', et_gini), ('et_entropy', et_entropy)], weights=[1, 1, 2, 1], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et_gini2 = ExtraTreesClassifier(n_estimators=10, min_samples_leaf=5, max_features=62, criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.70167064,  0.7052506 ,  0.7052506 ,  0.67899761,  0.72998805])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cross_val_score(voting1, dataX, dataY, cv=5, n_jobs=-1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70423150072853669"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68274808028445721"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = cross_val_score(et_gini2, dataX, dataY, cv=5, n_jobs=-1)\n",
    "np.average(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Best Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=5000, min_samples_leaf=5, max_features=62, n_jobs=-1, criterion='gini')\n",
    "rf2 = RandomForestClassifier(n_estimators=5000, min_samples_leaf=5, max_features=62, n_jobs=-1, criterion='entropy')\n",
    "et1 = ExtraTreesClassifier(n_estimators=5000, min_samples_leaf=5, max_features=62, n_jobs=-1, criterion='gini')\n",
    "et2 = ExtraTreesClassifier(n_estimators=5000, min_samples_leaf=5, max_features=62, n_jobs=-1, criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.69689737  0.70883055  0.71002387  0.66348449  0.73715651]\n",
      "--- 259.82 mins ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ensemble1 = VotingClassifier(estimators=[('rf1', rf1), ('rf2', rf2), ('et1', et1), ('et2', et2)], voting='hard')\n",
    "ensemble1_cv_score = cross_val_score(ensemble1, dataX, dataY, cv=5, n_jobs=-1)\n",
    "print ensemble1_cv_score\n",
    "print(\"--- %.2f mins ---\" % ((time.time() - start_time)/60))\n",
    "# below time should be 25.982 mins\n",
    "print np.average(ensemble1_cv_score)\n",
    "os.system('say \"your program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70327855763994029"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(ensemble1_cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "param_dist = {\"max_features\": sp_randint(20, 85),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "n_iter_search = 60\n",
    "rf_grid = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=n_iter_search, cv = 5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 21.00 mins ---\n",
      "0.715445213655\n",
      "{'max_features': 65, 'criterion': 'entropy', 'min_samples_leaf': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rf_grid.fit(dataX, dataY)\n",
    "print(\"--- %.2f mins ---\" % ((time.time() - start_time)/60))\n",
    "print rf_grid.best_score_\n",
    "print rf_grid.best_params_\n",
    "os.system('say \"your first program has finished\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=500, n_jobs=-1)\n",
    "et_grid = RandomizedSearchCV(estimator=et, param_distributions=param_dist, n_iter=n_iter_search, cv = 5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 43.19 mins ---\n",
      "0.715445213655\n",
      "{'max_features': 81, 'criterion': 'entropy', 'min_samples_leaf': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "et_grid.fit(dataX, dataY)\n",
    "print(\"--- %.2f mins ---\" % ((time.time() - start_time)/60))\n",
    "print et_grid.best_score_\n",
    "print et_grid.best_params_\n",
    "os.system('say \"your second program has finished\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_dist2 = {\n",
    "    'max_depth': sp_randint(3, 15),\n",
    "    'learning_rate': [0.3, 0.2, 0.15, 0.1, 0.05, 0.01],\n",
    "    'colsample_bytree': sp_uniform(0.4, 0.55),\n",
    "    'min_child_weight': sp_randint(1, 10)\n",
    "}\n",
    "\n",
    "xg = XGBClassifier(n_estimators=500)\n",
    "xg_grid = RandomizedSearchCV(estimator=xg, param_distributions=param_dist2, n_iter=n_iter_search, cv = 5, n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "xg_grid.fit(dataX, dataY)\n",
    "print(\"--- %.2f mins ---\" % ((time.time() - start_time)/60))\n",
    "print xg_grid.best_score_\n",
    "print xg_grid.best_params_\n",
    "os.system('say \"your x g boost program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try with more estimators\n",
    "start_time = time.time()\n",
    "xg2 = XGBClassifier(n_estimators=10000, learning_rate=0.15, colsample_bytree=0.473923, max_depth=9, min_child_weight=5)\n",
    "xg2_score = cross_val_score(xg2, dataX, dataY, cv=5, n_jobs=-1)\n",
    "print np.average(xg2_score)\n",
    "print xg2_score\n",
    "print(\"--- %.2f mins ---\" % ((time.time() - start_time)/60))\n",
    "os.system('say \"your x g boost c v has finished\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoosted Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#param_dist_adrf = {\n",
    "#    'n_estimators': sp_randint(5, 15),\n",
    "#    'learning_rate': sp_uniform(0, 1)\n",
    "#}\n",
    "adarf = RandomForestClassifier(n_estimators=500, max_features=65, criterion='entropy', min_samples_leaf=2, n_jobs=-1)\n",
    "ada = AdaBoostClassifier(base_estimator=adarf, n_estimators=10)\n",
    "\n",
    "#ada_grid = RandomizedSearchCV(estimator=ada, param_distributions=param_dist_adrf, n_iter=30, cv = 5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4.28 mins ---\n",
      "0.723328286328\n",
      "[ 0.71718377  0.72911695  0.73150358  0.69331742  0.74551971]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ada_cv_score = cross_val_score(ada, dataX, dataY, cv=5, n_jobs=-1)\n",
    "print(\"--- %.2f mins ---\" % ((time.time() - start_time)/60))\n",
    "print np.average(ada_cv_score)\n",
    "print ada_cv_score\n",
    "os.system('say \"your adaboosted random forest program has finished\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dist3 = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"base_estimator__max_depth\" : sp_randint(1, 11),\n",
    "              \"base_estimator__max_features\" : sp_randint(10, 100),\n",
    "              \"n_estimators\": sp_randint(1000, 10000)\n",
    "             }\n",
    "dt = DecisionTreeClassifier()\n",
    "ada2 = AdaBoostClassifier(base_estimator=dt, learning_rate=1)\n",
    "ada2_grid = RandomizedSearchCV(estimator=ada2, param_distributions=param_dist3, cv = 5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 14.68 mins ---\n",
      "0.657197421819\n",
      "{'n_estimators': 3449, 'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 1, 'base_estimator__max_features': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ada2_grid.fit(dataX, dataY)\n",
    "print(\"--- %.2f mins ---\" % ((time.time() - start_time)/60))\n",
    "print ada2_grid.best_score_\n",
    "print ada2_grid.best_params_\n",
    "os.system('say \"your adaboost program has finished\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models and Ensembles for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_sub = RandomForestClassifier(n_estimators=5000, max_features=65, criterion='entropy', min_samples_leaf=2, n_jobs=-1)\n",
    "et_sub = ExtraTreesClassifier(n_estimators=5000, max_features=81, criterion='entropy', min_samples_leaf=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 24.11 mins ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RF with 100000 trees\n",
    "start_time = time.time()\n",
    "rf_sub1 = RandomForestClassifier(n_estimators=100000, max_features=65, criterion='entropy', min_samples_leaf=2, n_jobs=-1)\n",
    "rf_sub1.fit(dataX, dataY)\n",
    "print(\"--- %.2f mins ---\" % ((time.time() - start_time)/60))\n",
    "os.system('say \"Master, your random forest program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict data and write to file.\n",
    "rf_sub1_predict = rf_sub1.predict(test_data)\n",
    "\n",
    "f = open(\"RandomForest5.csv\", \"w\")\n",
    "f.write(\"Id,Prediction\\n\")\n",
    "for x in range(len(rf_sub1_predict)):\n",
    "    f.write(str(x+1) + \",\" + str(int(rf_sub1_predict[x])) + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "os.system('say \"Master, your file has been created.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CURRENT BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 30.91 mins ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adaboosted Random Tree\n",
    "start_time = time.time()\n",
    "adarf_sub = RandomForestClassifier(n_estimators=10000, max_features=65, criterion='entropy', min_samples_leaf=2, n_jobs=-1)\n",
    "ada_sub = AdaBoostClassifier(base_estimator=adarf_sub, n_estimators=10)\n",
    "ada_sub.fit(dataX, dataY)\n",
    "print(\"--- %.2f mins ---\" % ((time.time() - start_time)/60))\n",
    "\n",
    "os.system('say \"Your adaboost program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict data and write to file.\n",
    "ada_sub_predict = ada_sub.predict(test_data)\n",
    "\n",
    "f = open(\"AdaBoostRF2.csv\", \"w\")\n",
    "f.write(\"Id,Prediction\\n\")\n",
    "for x in range(len(ada_sub_predict)):\n",
    "    f.write(str(x+1) + \",\" + str(int(ada_sub_predict[x])) + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "os.system('say \"Your file has been created.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to Improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_ada = {'n_estimators': sp_randint(1, 30), 'learning_rate': [0.1, 0.5, 0.8, 0.01, 0.05]}\n",
    "\n",
    "# Adaboosted Random Tree\n",
    "start_time = time.time()\n",
    "adarf_sub2 = RandomForestClassifier(n_estimators=100, max_features=65, criterion='entropy', min_samples_leaf=2, n_jobs=-1)\n",
    "ada_sub2 = AdaBoostClassifier(base_estimator=adarf_sub2)\n",
    "\n",
    "ada_grid = RandomizedSearchCV(estimator=ada_sub2, param_distributions = params_ada, n_iter=60, cv = 5, n_jobs=-1)\n",
    "\n",
    "\n",
    "ada_grid.fit(dataX, dataY)\n",
    "print ada_grid.best_params_\n",
    "print ada_grid.best_score_\n",
    "print(\"--- %.2f mins ---\" % ((time.time() - start_time)/60))\n",
    "\n",
    "os.system('say \"Your adaboost search has finished\"')\n",
    "\n",
    "# Run on Wing IDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.59 mins ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adaboosted Random Tree\n",
    "start_time = time.time()\n",
    "adarf_sub2 = RandomForestClassifier(n_estimators=100, max_features=65, criterion='entropy', min_samples_leaf=2, n_jobs=-1)\n",
    "ada_sub2 = AdaBoostClassifier(base_estimator=adarf_sub2, n_estimators=30)\n",
    "ada_sub2.fit(dataX, dataY)\n",
    "print(\"--- %.2f mins ---\" % ((time.time() - start_time)/60))\n",
    "\n",
    "os.system('say \"Your adaboost program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict data and write to file.\n",
    "ada_sub2_predict = ada_sub2.predict(test_data)\n",
    "\n",
    "f = open(\"AdaBoostRF3.csv\", \"w\")\n",
    "f.write(\"Id,Prediction\\n\")\n",
    "for x in range(len(ada_sub2_predict)):\n",
    "    f.write(str(x+1) + \",\" + str(int(ada_sub2_predict[x])) + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "os.system('say \"Your file has been created.\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 19.30 mins ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with more estimators\n",
    "start_time = time.time()\n",
    "xg2 = XGBClassifier(n_estimators=10000, learning_rate=0.15, colsample_bytree=0.473923, max_depth=9, min_child_weight=5)\n",
    "xg2.fit(dataX, dataY)\n",
    "print(\"--- %.2f mins ---\" % ((time.time() - start_time)/60))\n",
    "\n",
    "os.system('say \"Master, your adaboost program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict data and write to file.\n",
    "xg2_predict = xg2.predict(test_data)\n",
    "\n",
    "f = open(\"XGB1.csv\", \"w\")\n",
    "f.write(\"Id,Prediction\\n\")\n",
    "for x in range(len(xg2_predict)):\n",
    "    f.write(str(x+1) + \",\" + str(int(xg2_predict[x])) + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "os.system('say \"Master, your file has been created.\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
